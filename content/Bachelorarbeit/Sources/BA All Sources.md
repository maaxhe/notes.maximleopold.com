## Paper Zitate & Kommentare 


### De Vries & Baldauf (2021) - Journal of Neuroscience

De Vries, I. E. J., Marinato, G., & Baldauf, D. (2021). Decoding Object-Based Auditory Attention from Source-Reconstructed MEG Alpha Oscillations. _The Journal of Neuroscience_, _41_(41), 8603–8617. [https://doi.org/10.1523/JNEUROSCI.0583-21.2021](https://doi.org/10.1523/JNEUROSCI.0583-21.2021) 


### Rauschecker (2011) - Hearing Research

Rauschecker, J. P. (2011). An expanded role for the dorsal auditory pathway in sensorimotor control and integration. _Hearing Research_, _271_(1–2), 16–25. [https://doi.org/10.1016/j.heares.2010.09.001](https://doi.org/10.1016/j.heares.2010.09.001)

- [x] Paper durchgelesen?

also es ist gar nicht so einfach, monkeys mit menschen zu vergleichen, weil die anatomy in beiden unterschiedlich ist - das lese ich daraus.

- The role of the antero-ventral auditory processing stream in auditory object identification, or as a “what”-pathway, has become largely undisputed
- role of the postero-dorsal auditory pathway for spatial hearing
- whereas monkeys use their dorsal stream for space processing, humans use it for speech
- Although it is common knowledge that brainstem mechanisms play an important role in the processing of spatial attributes of sounds (Irvine, 1992; King and Nelken, 2009; Knudsen and Konishi, 1978), early studies have also suggested a role for auditory cortex in sound localization (Diamond et al., 1956; Heffner and Masterton, 1975; Ravizza and Masterton, 1972).

in monkeys: 
- In rhesus monkeys, core areas A1 and R (the “primary” and “rostral” fields, respectively), are surrounded by secondary belt areas (Kaas and Hackett, 2000). Both lateral and medial belt (LB and MB) neurons respond better to band-passed noise bursts than to pure tones (Kusmierek and Rauschecker, 2009; Rauschecker et al., 1995). Comparing core and belt, spatially tuned neurons are present in A1 but are found at a much higher density in the caudo-medial belt field (CM) (Rauschecker et al., 1997; Recanzone, 2000). When monkeys are trained in an auditory localization task, the firing rate of neurons in CM correlates more tightly with behavioral performance than that of neurons in A1, which is a strong indication that CM plays an important role in sound localization (Recanzone et al., 2000). Such localization is most likely accomplished on the basis of a population code (Miller and Recanzone, 2009).
- Connectivity studies in rhesus monkeys (Rauschecker et al., 1997) have shown that at least one of the caudal belt regions receives its subcortical input via a separate pathway than core areas A1 and R.

### Rauschecker & Afsahi (2023) - Journal of Comparative Neurology

Rauschecker, J. P., & Afsahi, R. K. (2023). Anatomy of the auditory cortex then and now. _Journal of Comparative Neurology_, _531_(18), 1883–1892. [https://doi.org/10.1002/cne.25560](https://doi.org/10.1002/cne.25560)

- [x] Paper durchgelesen?

- the primary auditory cortex (A1) and the rostral area (R), respond well to pure tones (PTs) and are narrowly tuned to frequency, whereas normal responsiveness at later stages of auditory cortical processing (area CM) depends on the integrity of the core
- anterolateral area (AL) projects to rostral parabelt (RB), and the caudolateral area (CL) projects to caudal parabelt (CB). In addition, a middle lateral area (ML) was found that projected to both RB and CB
- Injections into area AL led to label in the ventrolateral prefrontal cortex (VLPFC), whereas injections into area CL led to label in the dorsolateral prefrontal cortex (DLPFC)

pathways
- projection from AL in the auditory belt to VLPFC subserves the same purpose of object working memory as in the visual domain; and the projection from CL conveys auditory spatial information to support auditory spatial working memory

anteroventral
- anteroventrally directed pathway from rostral belt projects to VLPFC and provides the anatomical-physiological substrate for the identification of auditory objects

postero-dorsal
- postero-dorsal pathway from the caudal belt projects to DLPFC, providing the substrate for auditory spatial analysis: a ‘where’-stream.
- participation of posterior temporal and parietal cortices in auditory space processing
- Some of these and other studies also demonstrated a participation of DLPFC in spatial hearing (Belin et al., 2002; Lewald et al., 2008; Weeks et al., 2000)
- The current dorsal-stream model postulates that posterior parietal areas may serve as a relay station between auditory centers and the PMC

### Rolls et al. (2023) - Cerebral Cortex

Rolls, E. T., Rauschecker, J. P., Deco, G., Huang, C.-C., & Feng, J. (2023). Auditory cortical connectivity in humans. _Cerebral Cortex_, _33_(10), 6207–6227. [https://doi.org/10.1093/cercor/bhac496](https://doi.org/10.1093/cercor/bhac496)

- [x] Paper durchgelesen?

Rolls brain is whole brain 

aber was wir machen wollen, 

general:
- the auditory cortex is described as having core (corresponding to primary and primarylike auditory cortex), then belt (which surrounds the core), and then parabelt fields, all of which contain several subfields
- Early Auditory division: Area 52, A1 Primary Auditory Cortex, LBelt Lateral Belt Complex, MBelt Medial Belt Complex, PBelt ParaBelt Complex, PFcm (which is part of the parietal cortex), and RI RetroInsular Area. Auditory Association division: A4 Auditory 4 Complex, A5 Auditory 5 Complex, TA2, STGa, STSda Area STS dorsal anterior, STSdp Area STS dorsal posterior, STSva Area STS ventral anterior, and STSvp Area STS ventral posterior. It is noted that the HCP-MMP atlas sometimes uses dorsal vs ventral as descriptors following nomenclature in non-human primates, and that these correspond to superior and inferior in humans.

belt and parabelt:
- belt neurons respond best to band-passed noise of a specific frequency and bandwidth; and parabelt neurons respond to increasingly complex sounds.

ventral:
- Consistent with this being a “what” ventral auditory stream, these STS regions then have effective connectivity to TPOJ1, STV, PSL, TGv, TGd, and PGi, which are language-related semantic regions connecting to Broca’s area, especially BA45.
- ventral auditory pathway is involved in the decoding of spectrally complex sounds (“auditory objects”), which includes the decoding of speech sounds ("speech perception") and their ultimate linking to meaning in humans.
- areas
	- STGa connects to part of Broca’s area, area 45 (Figs. 2-4). STGa is proposed to be part of a superior (i.e. anatomically dorsal) bank of the STS cortex semantic system including STSda and STSdp, which is involved in multimodal auditory and corresponding visual motion information
	- dorsal bank STS regions are therefore important in linking motion-related changes in the sight of the face to the dynamically changing auditory input, and this is likely to be useful for identifying who in a group is making the vocalization, in maximizing the ability to decode information in noisy environments in order to understand speech, in maximizing the information in social signals by combining the auditory and visual components, etc. In the sense that this processing provides evidence about what the message is, this could be considered as a type of ventral stream “what” semantic processing.
	- superior/dorsal bank STS
		- This “superior/dorsal bank STS cortex system” thus enables multimodal representations including visual, auditory, and probably also somatosensory via PGi, to gain access to the language system (Rolls et al. 2022e). This is a major output of cortical visual and auditory processing for use in language, described in more detail elsewhere

--> warum hat STS einfluss von PGi, das ist doch ganz woanders?? ^579d43

dorsal: 
- anatomy:
	- A4 and A5 also have effective connectivity to MT and MST, which connect to superior parietal regions forming a dorsal auditory “where” stream involved in actions in space. Connections of PBelt, A4, and A5 with BA44 may form a language-related dorsal stream.
	- Inferior parietal and premotor cortices are all part of this dorsal stream network
- tasks
	- An auditory dorsal pathway is involved in sensorimotor integration and control (Rauschecker 2011), and in humans plays a role in speech production as well as categorization of phonemes during speech processing (Rauschecker 2012).
	- it has presumably evolved as a substrate for sensorimotor processing, connecting sensory, and motor cortical systems with each other and the basal ganglia (Rauschecker 2018a; Archakov et al. 2020), thus permitting the learning of sequences and the origin of both language and music (Rauschecker 2018b).
	- functional connectivity, which is evident in Fig. 5 between A4, the PBelt, etc. and parietal 7AL, 7Am, and 7PC, and is also supported by the diffusion tractography showing connections between similar regions (Fig. 6). These auditory inputs to dorsal-stream parietal areas could be used to shift visual attention and eye position to a source of sound, to help track moving noisy objects such as f lying birds and predators (e.g. alarm calls for eagles versus snakes (Seyfarth and Cheney 2010)), or keeping track of the location of a predator when running away, and performing actions in the dark for objects that can be detected by their sound.

other regions: 
- issue arises of whether A5 is part of a dorsal or ventral auditory stream
- Lbelt, Pbelt, A4 and A5 have effective connectivity with MT/MST regions as indicated, and this may be part of a dorsal “where” stream leading to intraparietal and area 7 regions

V5
- auditory cortical region A5 has connectivity with inferior frontal gyrus regions IFJa and IFSp, which are implicated in short-term working memory for the ventral streams

PFC
- OFC/vmPFC
	- Moreover, neurons can respond to auditory stimuli such as vocalization both in the STS regions (Baylis et al. 1987) and in the orbitofrontal cortex, which receives connections from the STS (Rolls et al. 2006). The connectivity described here helps to provide a functional framework for the processing streams involved in these types of function.
	- Inputs related to reward and punishment from, for example, the ventromedial prefrontal cortex (vmPFC) (10r, 10v, 10d), and orbitofrontal cortex (a47r) (Rolls et al. 2022g) reach STS auditory–visual cortical regions where objects, faces, and their semantic meaning are represented (Rolls et al. 2022e), rather than earlier stages of auditory cortical processing (Figs. 2-4). Correspondingly, STS regions have effective connectivity with some orbitofrontal/vmPFC regions in which neurons respond to vocalization and the face movements that produce them

### Ahveninen et al. (2006) - PNAS

Ahveninen, J., Jääskeläinen, I. P., Raij, T., Bonmassar, G., Devore, S., Hämäläinen, M., Levänen, S., Lin, F.-H., Sams, M., Shinn-Cunningham, B. G., Witzel, T., & Belliveau, J. W. (2006). Task-modulated "what" and "where" pathways in human auditory cortex. _Proceedings of the National Academy of Sciences_, _103_(39), 14608–14613. [https://doi.org/10.1073/pnas.0510480103](https://doi.org/10.1073/pnas.0510480103)

- [x] Paper durchgelesen?

- Selective attention is known to support both sound localization and recognition, but it is unclear how representations of auditory space and identity are top-down modulated in the human auditory cortex.

- double dissociation in response adaptation to sound pairs with phonetic vs. spatial sound changes, demonstrating that the human nonprimary auditory cortex indeed processes speech-sound identity and location in parallel anterior ‘‘what’’ (in anterolateral Heschl’s gyrus, anterior superior temporal gyrus, and posterior planum polare) and posterior ‘‘where’’ (in planum temporale and posterior superior temporal gyrus) pathways as early as 70 –150 ms from stimulus onset. Our data further show that the ‘‘where’’ pathway is activated 30 ms earlier than the ‘‘what’’ pathway, possibly enabling the brain to use top-down spatial information in auditory object perception.
- accumulating evidence that nonprimary auditory cortex regions posterior to the Heschl’s gyrus (HG) are involved in spatial processing
- Selective attention may thus be based on short-term plasticity of auditory cortex, increasing the neurons’ selectivity for relevant information, instead of simple amplification of neuronal responses (proposed to govern attentional modulation of visual cortices) (46, 56). Such featurespecific modulation of neuronal receptive fields by selective attention may facilitate adjustment and calibration of the perceptual system based on the particular acoustic environment and task requirements.
- **‘‘where’’ stream is activated significantly earlier ( 30 ms in ECD models) than the anterior ‘‘what’’ stream.**
	- the posterior auditory ‘‘where’’ pathway could accomplish rapid and coarse stimulus analysis required for shifting and maintaining attention to the features of a relevant auditory object (50), thus enabling the human brain to use top-down spatial information in auditory object perception.
	- anterolateral HG, parts of the anterior STG, and PP process auditory object identity and that regions posterior to HG, including parts of PT and posterior STG, process sound location features (see Fig. 2). ^dfae6d



### Hickok & Poeppel (2004) - Cognition

Hickok, G., & Poeppel, D. (2004). Dorsal and ventral streams: A framework for understanding aspects of the functional anatomy of language. _Cognition_, _92_(1–2), 67–99. [https://doi.org/10.1016/j.cognition.2003.10.011](https://doi.org/10.1016/j.cognition.2003.10.011)

_The functional anatomic framework for language which is presented in this paper is based on a rather old insight in language research dating back at least to the 19th century (e.g. Wernicke, 1874/1969), namely that sensory speech codes must minimally interface with two systems: a conceptual system and a motor–articulatory system._

- we will argue that sensory representations of speech in auditory-related cortices (bilaterally) interface (i) with conceptual representations via projections to portions of the temporal lobe (the ventral stream), and (ii) with motor representation via projections to temporal –parietal regions (the dorsal stream). Before presenting the detail
- In the last several years, however, there has been mounting evidence suggesting that the concept “where” may be an insufficient characterization of the dorsal stream (Milner & Goodale, 1995). Instead, it has been proposed that the dorsal visual stream is particularly geared for visuo-motor integration, as required in visually guided reaching or orienting responses.1 According to this view, dorsal stream systems appear to compute coordinate transformations – for example, transform representations in retino-centric coordinates to head-, and body-centered coordinates that allows visual information to interface with various motor-effector systems which act on that visual input (Andersen, 1997; Rizzolatti, Fogassi, & Gallese, 1997).
- While there is general agreement regarding the role of the ventral stream in auditory “what” processing, the functional role of the dorsal stream is debated.
- we have put forward a third hypothesis, that the dorsal auditory stream is critical for auditory – motor integration (Hickok & Poeppel, 2000), similar to its role in the visual domain

- ventral stream, which is involved in mapping sound onto meaning, and a dorsal stream, which is involved in mapping sound onto articulatory-based representations.
- The ventral stream projects ventro-laterally toward inferior posterior temporal cortex (posterior middle temporal gyrus) which serves as an interface between sound-based representations of speech in the superior temporal gyrus (again bilaterally) and widely distributed conceptual representations. The dorsal stream projects dorso-posteriorly involving a region in the posterior Sylvian fissure at the parietal – temporal boundary (area Spt), and ultimately projecting to frontal regions. This network provides a mechanism for the development and maintenance of “parity” between auditory and motor representations of speech.
- Although the proposed dorsal stream represents a very tight connection between processes involved in speech perception and speech production, it does not appear to be a critical component of the speech perception process under normal (ecologically natural) listening conditions, that is, when speech input is mapped onto a conceptual representation.
- We also propose some degree of bi-directionality in both the dorsal and ventral pathways.

![[Hickok, Poeppel 2004 auditory streams.png]]
![[Hickok Poeppel fig 2 auditory stream.png]]
- Language processing systems can be viewed as a set of transformations over representations (not necessarily in series), for example, mapping between an acoustic input and a conceptual representation (as in comprehension), or between a conceptual representation and a sequence of motor gestures (as in production). Early stages of this mapping process on the input side – for example, cochlear, brain stem and thalamic processing as well as at least early cortical auditory mapping – likely perform transformations on the acoustic data that are relevant to linguistic as well as non-linguistic auditory perception. Because these early processing stages are not uniquely involved in language perception, they are often dismissed as being merely “auditory” areas and not relevant to understanding language processing. But clearly each stage in this analytic process interacts with other stages in important ways: the computations performed at one level depend on the input received from other levels, and therefore each transformation plays a role in the entire process of mapping sound onto meaning (or meaning onto motor articulation).
- An important consequence of this view of language processes as a set of computations or mappings between representations is that the neural systems involved in a given language operation (task) will depend to some extent on what representation is being mapped onto.
	- For example, speech input which is mapped onto a conceptual representation (as in comprehension tasks) will clearly involve a set of computations which is non-identical to those involved in mapping that same input onto a motor articulatory representation (as in a repetition task). Of course, the mapping stages in these two tasks will be shared up to some point, but they must diverge in accordance with the different requirements entailed by the endpoints of the mapping process. The upshot is that the particular task which is employed to investigate the neural organization of language (that is, the mapping operation the subject is asked to compute) determines which neural circuit is predominantly activated.
- laut Hickok geht es vom "superior temporal gyrus (STG) bilaterally. This cortical processing system then diverges into two processing streams, a ventral stream, which is involved in mapping sound onto meaning, and a dorsal stream, which is involved in mapping sound onto articulatory-based representations."
	- ventral
		- The ventral stream projects ventro-laterally and involves cortex in the superior temporal sulcus (STS) and ultimately in the posterior inferior temporal lobe (pITL, i.e. portions of the middle temporal gyrus (MTG) and inferior temporal gyrus (ITG)).3 These pITL structures serve as an interface between sound-based representations of speech in STG and widely distributed conceptual representations (Damasio, 1989). In psycholinguistic terms, this sound – meaning interface system may correspond to the lemma level of representation (Levelt, 1989).
		- ventro-lateral portions of the STG, extending into both anterior and posterior portions of the STS, appear to respond best to complex spectro-temporal signals such as speech
		- All of these observations suggest that cortex in ventro-lateral portions of the STG, including the STS (stippled portion in Fig. 1B), comprises advanced stages in the auditory processing hierarchy which are critical to phoneme-level processing
	- dorsal
		- The dorsal stream projects dorso-posteriorly toward the parietal lobe and ultimately to frontal regions. Based on available evidence in the literature (Jonides et al., 1998), we previously hypothesized that the posterior portion of this dorsal stream was located in the posterior parietal lobe (areas 7, 40). Recent evidence, however, suggests instead that the critical region is deep within the posterior aspect of Sylvian fissure at the boundary between the parietal and temporal lobes, a region we have referred to as area Spt (Sylvian– parietal – temporal) (Buchsbaum, Humphries, & Hickok, 2001; Hickok et al., 2003). Area Spt, then, is a crucial part of a network which performs a coordinate transform, mapping between auditory representations of speech and motor representations of speech
- We also propose bi-directionality in both the dorsal and ventral pathways. Thus, in the ventral stream, pITL networks mediate the relation between sound and meaning both for perception and production
- Our claim is simply that there exists a cortical network which performs a mapping between (or binds) acoustic –phonetic representations on the one hand, and conceptual – semantic representations on the other.
	- we hypothesize that sectors of the left STG participate not only in sub-lexical aspects of the perception of speech, but also in sub-lexical aspects of the production of speech (again, perhaps non-symmetrically).
- In the dorsal stream, we suggest that temporal –parietal systems can map auditory speech representations onto motor representations ^a92df4
- When the neural organization of speech perception (or acoustic –phonetic processing, we will use these terms interchangeably) is examined from the perspective of auditory comprehension tasks, the picture that emerges is one in which acoustic –phonetic processing is carried out in the STG bilaterally (although asymmetrically) and then interfaces with conceptual systems via a left-dominant network in posterior inferior temporal regions (e.g. MTG, ITG, and perhaps extending to regions around the temporal parietal – occipital boundary). The arguments supporting this claim follow in Sections 4.1 and 4.2. Sentence-level processes may additionally involve anterior temporal regions (see Section 4.4).
- while Wernicke’s area is classically associated with the left STG, Wernicke himself indicates that both hemispheres can represent “sound images” of speech. According to Wernicke (1874/1969), the left STG becomes dominant for language processes by virtue of its connection with the left-lateralized motor speech area
- Another line of evidence comes from imaging studies of “semantic processing” (typically lexical semantics) which generally implicate inferior posterior temporal regions and posterior parietal cortex (Binder et al., 1997).9 This distribution of activation corresponds quite well to the distribution of lesions associated with transcortical sensory aphasia (TSA) which lends support to the claim of meaning-based integration networks in posterior ITL (again perhaps extending to regions around the temporal –parietal – occipital junction).
- Taken together, these observations (including those from SD) are consistent with our claim of a sound –meaning mapping system in posterior ITL.
- Finally, Indefrey and Levelt (this volume), in their meta-analysis of a large number of functional imaging studies, have identified the middle portion of the MTG as a site which plays a role in “conceptually-driven lexical retrieval” during speech production; this region was also shown to be consistently active during speech perception in their analysis. This stage in processing is compatible with our sound – meaning interface.
- these data suggest a possible role for anterior temporal cortex in aspects of grammatical processing


### De Vries et al. (2021) - Journal of Neuroscience

De Vries, I. E. J., Marinato, G., & Baldauf, D. (2021). Decoding Object-Based Auditory Attention from Source-Reconstructed MEG Alpha Oscillations. _The Journal of Neuroscience_, _41_(41), 8603–8617. [https://doi.org/10.1523/JNEUROSCI.0583-21.2021](https://doi.org/10.1523/JNEUROSCI.0583-21.2021)

We thus demonstrate anticipatory alpha oscillations to underlie top-down control of object-based auditory attention in complex naturalistic scenes.

subjects who were better prepared (i.e., attended better to the correct stream right before the repetition, as indicated by higher alpha classification accuracy) responded faster to the repetition. We did not observe such an effect for accuracy (Rho = 0.26, p = 0.35). Albeit speculative, these two results suggest a causal role for oscillatory alpha activity in object-based auditory attention since significant alpha classification earlier during the trial predicted subsequent behavioral performance.

- paper could show alpha connections from IFJ to auditory cortex -> Figure 3d


### Romanski et al. (1999) - Nature Neuroscience

Romanski, L. M., Tian, B., Fritz, J., Mishkin, M., Goldman-Rakic, P. S., & Rauschecker, J. P. (1999). Dual streams of auditory afferents target multiple domains in the primate prefrontal cortex. _Nature Neuroscience_, _2_(12), 1131–1136. [https://doi.org/10.1038/16056](https://doi.org/10.1038/16056)

- separate auditory streams originate in caudal and rostral auditory cortex and target spatial and non-spatial domains of the frontal lobe
- three cochleotopically organized fields separated by frequency reversals, termed anterolateral (AL), middle-lateral (ML) and caudolateral (CL) areas, are mapped within the lateral belt17. Electrophysiological studies of the superior temporal region in nonhuman primates suggests that its anterior and posterior aspects may differ functionally
- These findings raise the possibility that separate thalamocortical and corticocortical streams exist in the auditory system just as they do in the visual system
- We recorded from the lateral auditory belt and parabelt cortices in the superior temporal region of four rhesus macaques and determined the best center frequency along each electrode penetration through lateral belt areas AL, ML and CL
- The most anterior field, AL, had neuronal responses that ranged from 12.5 kHz at its most anterior edge down to 0.5 kHz where a frequency reversal occurred at its caudal edge, the point where area ML began. The best center frequencies in ML ranged from 0.5 kHz at its rostral edge to 20 kHz caudally just before the frequency reversal that marked the beginning of the caudal field, CL. The best frequencies in CL ranged from 20 kHz to 1 kHz. At the conclusion of the electrophysiological recordings, four to six distinguishable anatomical tracers were distributed among AL, ML and CL.
- projections from area CL targeted the dorsal periarcuate cortex (area 8a, frontal eye fields) and the caudal principal sulcus (area 46) as well as the caudal inferior convexity (areas 12 vl and 45; Fig. 3b, c and e) and, in two cases, premotor cortex (area 6d). The frontal pole (area 10) and the lateral orbital cortices (areas 11 and 12) were devoid of anterograde labeling from injections into the caudal auditory region
- frontal eye fields did not receive projections from anterior auditory area AL
- AL and CL projections converged, revealed a rostrocaudal topography within these convergence zones such that rostral labeling in the principal sulcus and inferior convexity resulted from AL injections (Fig. 3a, b and e), whereas projections from area CL accounted for caudal labeling in these areas (Fig. 3b, c and e). ML projections were usually a combination of those from anterior and posterior fields and involved less of the extreme frontal pole and frontal eye fields but did label the principal sulcus, lateral inferior convexity and lateral orbital cortex  (Fig. 3). These highly specific rostrocaudal topographical frontal–temporal connections suggest separate streams of auditory information that target distinct domains of the frontal lobes.
- Projections from areas AL and ML were densest within the rostral parabelt and rostral temporal lobe, including the rostral supratemporal plane. In contrast, the posterior parietal cortex areas 7a and 7ip were labeled from injections only in CL. In addition, the medial belt regions and the caudal half of the dorsal bank of the superior temporal sulcus received dense projections from areas ML and CL but only light projections from AL.

discussion
- One pathway, originating in CL, targets caudal dorsolateral prefrontal cortex (DLPFC); the other pathway, originating in AL, targets rostral and ventral prefrontal areas.
	- Because these dorsal and ventral prefrontal regions are respectively characterized as spatial and non-spatial functional domains2,27–29, a possible interpretation is that these separate streams originating from posterior and anterior auditory belt and parabelt cortices are analogous to the ‘where’ and ‘what’ streams of the visual system.
- DLPFC also receives auditory afferents from the caudal auditory belt region, suggesting its involvement in auditory processing as well.
- neuroimaging studies demonstrate involvement of the DLPFC in sound localization in humans
- Neurons in AL of anesthetized monkeys presented with acoustic stimuli (consisting of vocalizations and band-passed noise from a variety of different azimuth locations in free field) show better selectivity for particular monkey calls, whereas neurons in CL had significantly narrower spatial tuning.
	- support the notion of an auditory spatial stream originating in the caudal belt and parabelt region and targeting the DLPFC. The caudal belt and parabelt are also connected to the DLPFC via the posterior parietal cortex, which is itself involved in the localization of both visual and auditory signals
- In addition to this dorsal (and potentially ‘spatial’) auditory pathway, we present evidence for a second auditory stream originating in the anterior belt and parabelt region and terminating in the rostral and ventral frontal lobe. Neuroimaging studies demonstrate involvement of the frontal pole (area 10) of the rostral frontal lobe in verb generation, auditory working memory and musical consonance
- Our results substantiate findings of a connection between the ventral prefrontal cortex and anterior auditory cortical regions
- Ventrolateral frontal lobe regions 12 and 45, which make up the inferior convexity in the nonhuman primate, are situated just anterior to area 6, the premotor cortex43; it is suggested, on the basis of anatomical location and connections, that they represent the macaque homolog of Broca’s area4

### Cohen et al. (2016) - Springer

Cohen, Y. E., Bennur, S., Christison-Lagay, K., Gifford, A. M., & Tsunada, J. (2016). Functional Organization of the Ventral Auditory Pathway. In P. Van Dijk, D. Başkent, E. Gaudrain, E. De Kleine, A. Wagner, & C. Lanting (Eds.), _Physiology, Psychoacoustics and Cognition in Normal and Impaired Hearing_ (Vol. 894, pp. 381–388). Springer International Publishing. [https://doi.org/10.1007/978-3-319-25474-6_40](https://doi.org/10.1007/978-3-319-25474-6_40)

- [ ] paper gelesen?

- in latter parts of the auditory cortex, neurons encode the sensory evidence that forms an auditory decision and are causally involved in the decision process. Finally, in the prefrontal cortex, which receives input from the auditory cortex, neural activity reflects the actual perceptual decision. Together, these studies indicate that the ventral pathway contains hierarchical circuits that are specialized for auditory perception and scene analysis.

monkey: 
- In rhesus monkeys, this pathway begins in core auditory cortex—specifically, primary auditory cortex (A1) and the rostral field. These core areas project to the middle lateral (ML) and anterolateral belt (AL) regions of auditory cortex. In turn, these belt regions project directly and indirectly to the ventrolateral prefrontal cortex (vlPFC).

meta about dorsal: 
- It is important to briefly comment on the contribution of the dorsal (“spatial”) pathway to auditory perception (Rauschecker 2012; Cloutman 2013). Spatial information can act as a grouping cue to assist the segregation of an acoustic stimulus into discrete sounds. For example, when a rhythmic sequence of identical sound bursts is presented from a single location, it is often perceived as one source.

A1 controversial: 
- A1's role in auditory perception is controversial. Part of that controversy stems from the putative role of A1 in processing auditory “objects” (Nelken 2008). We will take the position that auditory objects are analogous to perceptual representations (i.e., sounds) (Bizley and Cohen 2013).

- human-imaging studies have revealed that regions of core auditory cortex are modulated by listener's reports of the identity of an ambiguous speech sound.
- choice-related activity may not reflect a casual contribution of the auditory cortex to decision-making but may simply reflect feedback from higher choice-sensitive areas (Nienborg and Cumming 2009) or the structure of the correlated noise (Nienborg et al. 2012).
- We found that neither ML nor AL activity was modulated by the monkeys' choices
- Interestingly, as noted above, the dorsal pathway also contributes to auditory perception; consistent with that notion, activity in the human parietal lobe is modulated by listeners' choices (Cusack 2005).

their model
- we propose a model in which auditory information is hierarchically organized and processed in the ventral pathway. In early parts of the auditory cortex, neural activity encodes the acoustic features of an auditory stimulus and become increasingly sensitive to complex spectrotemporal properties (Rauschecker and Tian 2000). In later regions of the auditory cortex, this information informs perceptual judgments.
- In core auditory cortex, neural activity codes the category membership of simple feature conjunctions. For example, categorical representations of frequency-contours have been identified (Ohl et al. 2001; Selezneva et al. 2006).
- Categories for more complex stimuli, such as speech sounds and vocalizations, can be found in the lateral belt (Chang et al. 2010; Steinschneider et al. 2011; Tsunada et al. 2011; Steinschneider 2013). For example, AL neurons respond categorically, and in a manner consistent with listeners' behavioral reports, to morphed versions of two speech sounds (“bad” and “dad”)
- superior temporal gyrus is categorically and hierarchically organized by speech sounds (Binder et al. 2000; Chang et al. 2010; Leaver and Rauschecker 2010): phoneme categories are found in the middle aspect; word categories in the anterior-superior aspect; and phrases in the most anterior aspect (DeWitt and Rauschecker 2012; Rauschecker 2012).
- vlPFC neurons represent the valence of food-related calls (e.g., high quality food vs. low quality food) (Gifford et al. 2005). That is, vlPFC neurons encode the “referential” information that is transmitted by vocalizations, independent of differences in their acoustic properties.
  
  ich glaube, das bezieht sich alles auf monkeys. 

### Scott et al. (2017) - Journal of Comparative Neurology

Scott, B. H., Saleem, K. S., Kikuchi, Y., Fukushima, M., Mishkin, M., & Saunders, R. C. (2017). Thalamic connections of the core auditory cortex and rostral supratemporal plane in the macaque monkey. _Journal of Comparative Neurology_, _525_(16), 3488–3513. [https://doi.org/10.1002/cne.24283](https://doi.org/10.1002/cne.24283)

- [x] gelesen

ventral stream in macaque monkeys includes the entirety of the supratemporal plane (STP) and adjacent superior temporal gyrus (STG), extending rostrally into the dorsal temporal pole (Poremba et al., 2003; Poremba et al., 2004; Petkov et al., 2008; Kikuchi et al., 2010; Ng et al., 2013; Fukushima et al., 2014; Scott et al., 2014).


### Rauschecker & Scott (2009) - Nature Neuroscience

Rauschecker, J. P., & Scott, S. K. (2009). Maps and streams in the auditory cortex: Nonhuman primates illuminate human speech processing. _Nature Neuroscience_, _12_(6), 718–724. [https://doi.org/10.1038/nn.2331](https://doi.org/10.1038/nn.2331)

The inferior parietal lobule (IPL), particularly the angular and supramarginal gyri (Brodmann areas 39 and 40), has also been linked to linguistic functions59, such as the 'phonological-articulatory loop'60. Functional imaging has confirmed this role, though activity varies with working memory task load61,62. However, the IPL does not seem to be driven by acoustic processing of speech: the angular gyrus (together with extensive prefrontal activation) is recruited when higher-order linguistic factors improve speech comprehension


IPL -> PGi
BA39, BA40
![[IPL BA39 und BA40.png]]()

monkeys:
- Anatomical tract tracing studies in monkeys support separate anterior and posterior projection streams in auditory cortex. The longrange connections from the surrounding belt areas project from anterior belt directly to ventrolateral prefrontal cortex (PFC) and from the caudal (posterior) belt to dorsolateral PFC.
	- --> heißt, dass die areale nicht zwingend nebeneinander sein müssen 
- neurons in the caudo-lateral belt (area CL) are more responsive to spatial location than neurons in core or anterior belt.

ideas: 
- Within these speech-specific regions of anterior superior temporal cortex, there may be subregions selective for particular speech-sound classes, such as vowels38,46, raising the possibility that phonetic maps have some anatomical implementation in anterior temporal lobe areas.
- it has been suggested that visual categories are formed in the lateral PFC50, which receives input from higher-order object representations in the anterior temporal lobe10. In audition, using species-specific communication sounds, Romanski et al.51 found clusters of neurons in the macaque ventrolateral PFC encoding similar complex calls, and category-specific cells encoding single semantic categories have also been reported
- The invariance problem in speech perception may be solved in the inferior frontal cortex, or by interactions between inferior frontal and anterior superior temporal cortex.

findings: 
- Evidence for a postero-dorsal stream in auditory spatial processing is just as strong, if not stronger, in the human as in nonhuman primates. Stroke studies as well as modern neuroimaging have shown that spatial processing in the temporo-parietal cortex is often right-lateralized in humans, contralateral to language. Generally, spatial neglect is more frequent and severe after damage to the right hemisphere.
- The inferior parietal lobule (IPL), particularly the angular and supramarginal gyri (Brodmann areas 39 and 40), has also been linked to linguistic functions59, such as the ‘phonological-articulatory loop’60. Functional imaging has confirmed this role, though activity varies with working memory task load61,62. However, the IPL does not seem to be driven by acoustic processing of speech: the angular gyrus (together with extensive prefrontal activation) is recruited when higher-order linguistic factors improve speech comprehension63, rather than by acoustic influences on intelligibility. Thus the parietal cortex is associated with more domain-general, linguistic factors in speech comprehension, rather than acoustic or phonetic processing.

multimodality: 
- There is now neurophysiological evidence that auditory caudal belt areas are not solely responsive to auditory input but show multimodal responses64,65: both caudal medial and lateral belt fields receive input from somatosensory and multisensory cortex. Thus any spatial transformations conducted in the postero-dorsal stream may be based on a multisensory reference frame
- Several studies of silent articulation68 and nonspeech auditory stimuli69 find activation in a posterior medial planum temporale region, within the postero-dorsal stream. The medial planum temporale in man70 has been associated with the representation of templates for ‘‘doable’’ articulations and sounds (not limited to speech sounds).
- the postero-medial planum temporale area described in the previous section is an auditory area important in the motor act of articulation

feedforward and feedbackward: 
- New work using high-resolution diffusion tensor imaging in humans has revealed that there are direct projections from the pars opercularis of Broca’s area (Brodmann area 44) to the IPL86, in addition to the ones from ventral premotor cortex87. With the known connections between parietal cortex and posterior auditory fields, this could form the basis for feed-forward connections between speech production areas and posterior temporal auditory areas (Fig. 5).
- Later posterior regions participate in the processing of auditory space and motion but seem to integrate input from several other modalities as well.
- The IPL could provide an ideal interface, where feed-forward signals from motor preparatory networks in the inferior frontal cortex and premotor cortex (PMC) can be matched with feedback signals from sensory areas
- The feedback signal coming to the IPL from pST, conversely, could be considered an ‘‘afference copy’’91 with relatively short latencies and high temporal precision92—a sparse but fast primal  sketch of ongoing sensory events93 that are compared with the predictive motor signal in the IPL at every instance.
nice to know, additional: 
- This finding is consistent with results from humans indicating that superior temporal areas are suppressed during speech production81,82 and that the response to one’s own voice is always less than the response to someone else’s.
- Spatial transformations may be one example of fast adaptations used by ‘internal models’ or ‘emulators’, as first developed in motor control theory.

![[suggested auditory pathways.png]]

![[dual stream auditory processing.png]]

from supplementary material: 
- the auditory input to parietal cortex is provided via  areas in posterior ST (pST), not directly from primary auditory cortex. This  polysynaptic pathway constitutes a processing stream, and pST serves as a  transformation stage between core and PPC
- Caudal belt and Tpt’s preferential frontal lobe connections are with the caudal  arcuate cortex (area 8a)9-11, which some authors have termed an “auditory  spatial zone
- A meta-analysis  of altogether 38 human imaging studies provided evidence that the vast majority  of auditory spatial studies involved activation of the postero-dorsal pathway (pST,  IPL, and SFS), whereas only two activated antero-ventral areas (aST, IFC)
- Imaging studies in humans have demonstrated specific  activation in pST with auditory motion24, 25 near the location of visual motion  areas MT and MST. Imaging studies that have tested moving auditory stimuli in  addition to stationary ones have reported that auditory motion leads to activation  in areas of pST and posterior parietal cortex that are adjacent to each other, with  motion being the more powerful stimulus14.

### Griffiths et al. (1998)
Griffiths, T. D., Rees, G., Rees, A., Green, G. G. R., Witton, C., Rowe, D., Büchel, C., Turner, R., & Frackowiak, R. S. J. (1998). Right parietal cortex is involved in the perception of sound movement in humans. _Nature Neuroscience_, _1_(1), 74–79. [https://doi.org/10.1038/276](https://doi.org/10.1038/276)

we have demonstrated human brain areas that are active specifically during the perception of sound movement. Both functional magnetic resonance imaging (fMRI) and positron emission tomography (PET) demonstrated the involvement of the right parietal cortex in sound movement perception with these stimuli.

A1:
- A1 was active during both tasks, but was not differentially activated by sound movement. No differential activation in A1 was demonstrated even if this area was treated as a region of interest for which a prior hypothesis existed, in which case statistical correction for multiple comparisons does not need to be made.

Parietal Cortex: 
- Another study15 demonstrated a dissociated deficit in sound movement detection due to a posterior right hemisphere lesion that was distinct from the auditory cortex.
- We therefore suggest that the posterior parietal activation we observe is due to perceptual processing of movement, rather than attention. Specifically, we hypothesize that a perceived representation of the stimulus movement exists in the posterior parietal cortex. This is in accord with neurophysiological studies suggesting a role for the posterior parietal cortex in the representation of abstract spatial information22.
- Neither the fMRI nor the PET experiments showed any increase in activation in auditory cortex during sound-movement perception. This is contrary to what might have been predicted from single-unit recordings in animals, showing neurons in the auditory cortex with selective responses to spatial sound cues
- The prefrontal areas receive projections from both ventral parietal cortex (area 7)33 and from area 7a/LIP in the monkey33,34. We suggest that the parietal areas, in conjunction with the prefrontal areas that we have demonstrated in the fMRI experiment, form a network involved in sound spatial perception and selective attention.

### Glasser et al. (2016) - Nature ^621d35

Glasser, M. F., Coalson, T. S., Robinson, E. C., Hacker, C. D., Harwell, J., Yacoub, E., Ugurbil, K., Andersson, J., Beckmann, C. F., Jenkinson, M., Smith, S. M., & Van Essen, D. C. (2016). A multi-modal parcellation of human cerebral cortex. _Nature_, _536_(7615), 171–178.

[https://doi.org/10.1038/nature18933](https://doi.org/10.1038/nature18933)

- The early auditory areas include A1, LBelt (Lateral Belt), MBelt (Medial Belt), PBelt (Para-Belt), and the retro-insular cortex (RI). These areas are surrounded by areas, OP2-3, OP1, PFcm, PSL, A4, Ig, and TA2.
- A1 is very heavily myelinated, even relative to its heavily myelinated surrounding neighbors

--> jetzt verstehe ich auch, warum die Belt regions so langgezogen sind. Sie umgeben einfach den A1 - das macht sie so langgezogen uns der ganze bereich hat eben sehr ähnliche connectivity. 

- Relative to its antero-medial neighbor area 52, the MBelt complex has more myelin (Panel B), is thicker (Panel D), and is activated vs deactivated in the LANGUAGE MATH and STORY contrasts (Panel J). Relative to its antero-lateral neighbor area TA2, MBelt has more myelin (Panel B), is thinner (Panel D), and is more activated in the LANGUAGE MATH and STORY contrasts (Panel J). Relative to its lateral neighbor PBelt, the MBelt complex has more myelin (Panel C) and is less activated in the language MATH and STORY contrasts (Panel J) and more activated in the EMOTION FACES-SHAPES contrast.
- We identified auditory association cortex as a region mainly on the superior temporal gyrus and within the superior temporal sulcus that is activated in the LANGUAGE STORY, MATH, and STORY-MATH contrasts. 
- It is strongly functionally connected with the inferior frontal gyrus, including areas 44, 45, and 47l.
- This auditory region likely becomes progressively less purely auditory and more multi-modal as one progresses inferiorly, anteriorly, and posteriorly (away from early auditory cortex, e.g. Main Text Figure 3).
- A4, A5, STSdp, STSda, STSvp, STSva, STGa, and TA2
- we have introduced largely novel terminology here, except that TA2 is based on the Von Economo and Koskinas parcellation (Triarhou, 2007a, b; von Economo and Koskinas, 1925). These areas are surrounded by PBelt, MBelt, PI, TGd, TE1a, TE1m, TE1p, PHT, TPOJ1, STV, and PSL.


more about [[A4]]:
A4’s supero-medial border with PBelt was covered in Section #10 Early Auditory Cortex. Relative to its inferior neighbor A5, area A4 differs in functional connectivity, and this gradient was primarily used to define the boundary (Panel D). A4 also has more myelin than A5 assessed statistically (Panel B), though the myelin gradient peak does not align with the functional connectivity gradient peak. Relative to its antero-medial neighbor TA2, area A4 has more myelin (Panel B), differs in functional connectivity (Panel D), is more activated in the LANGUAGE MATH and STORY contrasts (Panels E and F), and is less activated in the CUE-AVG contrast (Panel I).


more about [[A5]]
- A5 differs in functional connectivity (Panel D), and is more activated in the LANGAUGE STORY-MATH (Panel G) and TOM-RANDOM (Panel H) contrasts. Relative to its inferior neighbor STSdp, area A5 differs in many primary and non-primary task contrasts including more activation in the LANGAUGE MATH (Panel E) and STORY (Panel F) contrasts and less activation in the working memory (e.g Panel L) and RELATIONAL (e.g. Panel J) primary contrasts, and the FACE-AVG, TOM-RANDOM (Panel H), and FACES-SHAPES (Panel K) contrasts. Relative to its inferior neighbor STSda, area A5 again shows differences in a variety of task contrasts including markedly more activation in the LANGAUGE MATH contrast (Panel E), more activation in the TOOL-AVG contrast, markedly less activation in the TOM-RANDOM contrast (Panel H), and less activation in the CUE-AVG (Panel I) and FACES-SHAPES (Panel K) contrasts. Relative to its anterior neighbor STGa, area A5 has more myelin (Panel B) and differs in functional connectivity (Panel D).

more about [[STSdp]]:
- Relative to area STSvp on the inferior bank of the STS, area STSdp on the superior banks is has more myelin (Panel B), differs markedly in functional connectivity (Panel D), is more activated in the LANGUAGE MATH (Panel E), TOM-RANDOM (Panel H, especially in the right hemisphere), and MOTOR CUE-AVG (Panel I) contrasts. Relative to its anterior neighbor STSda in the superior bank of the STS, area STSdp has more myelin (Panel B), and differs markedly in its functional activation profile, being more activated in the CUE-AVG contrast (Panel I) and the RELATIONAL MATCH (Panel J), working memory (e.g. Panel L), SOCIAL TOM and other primary contrasts, and less active in the STORY-MATH contrast (Panel G).

![[Glasser fMRI auditory cortex.png]]


### Frühholz (2015) - NeuroImage 
Frühholz, S., Gschwind, M., & Grandjean, D. (2015). Bilateral dorsal and ventral fiber pathways for the processing of affective prosody identified by probabilistic fiber tracking. _NeuroImage_, _109_, 27–34. [https://doi.org/10.1016/j.neuroimage.2015.01.016](https://doi.org/10.1016/j.neuroimage.2015.01.016)

- Dorsal and ventral pathways for syntacto-semantic speech processing in the left hemisphere are represented in the dual-stream model of auditory processing.
- The results also suggest the existence of a dual-stream processing in the right hemisphere, and a general predominance of the dorsal pathways in both hemispheres underlying the neural processing of affective prosody in an extended temporo-frontal network.

- Recent studies (Friederici et al., 2006; Rauschecker and Scott, 2009; Saur et al., 2008) have predominantly identified left hemispheric processing pathways within a dual-stream model of auditory processing (Hickok and Poeppel, 2007). They include ventral pathways from anterior superior temporal gyrus (STG) to the anterior inferior frontal gyrus (IFG) and dorsal pathways, which project to the posterior IFG via the posterior STG (Hickok and Poeppel, 2007; Rauschecker and Scott, 2009).
	- bestätigt, was wir eh schon wissen

- Especially the dorsal pathway seems strongly left lateralized (Hickok and Poeppel, 2007). The ventral pathways convey sound-invariant meaning (Belin and Zatorre, 2000b; Rauschecker and Scott, 2009), such as speech semantics (Hagoort, 2005). 
- The dorsal pathways serve sound-to-motor mapping (Saur et al., 2008) and the processing of temporal auditory sequences (Belin and Zatorre, 2000b; Rauschecker and Scott, 2009), which are also necessary for the understanding of speech syntax (Friederici et al., 2006).
- Compared to a predominant role of the left brain for syntacto-semantic processing (Specht, 2014), the emotional  intonation in speech, that is the affective prosody, strongly, but not exclusively, activates regions in right STG and IFG (e.g. Alba-Ferrara et al., 2011; Beaucousin et al., 2007; Ethofer et al., 2006; Fruhholz et al., 2012).
- Ventral and dorsal pathways, for example, are supposed to originate in multiple STG seed regions (Friederici, 2011; Fruhholz et al., 2012). Furthermore, these pathways probably terminate in the anterior as well as in the posterior IFG (Fruhholz and Grandjean, 2013b)

STG-Regionen: 
- The right compared with left IFG showed a sensitivity to speech prosody during implicit attention, while left IFG subregions responded to affective prosody during both attentional conditions. All STG subregions showed a sensitivity to speech prosody both for the explicit and implicit attention condition, but right mid STG (mSTG) and left anterior STG (aSTG) showed stronger sensitivity during the explicit attention condition, whereby the latter regions showed a general main effect for the explicit compared with the implicit task, and thus might reflect a rather general evaluation of voices independent of the emotion. Furthermore, regions in the right posterior STG (fundus of the posterior superior temporal sulcus (fpSTS), posterior STG (pSTG)) and all left STG subregions were sensitive to the pitch and intensity variations in affective prosody, which are one of the main acoustic features of affective prosody (Banse and Scherer, 1996; Patel et al., 2011).

![[Fruehholz 2015 Figure 1.png]]


Und hier ventral/dorsal pathways according to Frühholz: 
![[Fruehholz 2015 Figure 2.png]]

Results: 
- The anterior STG (aSTG) was connected to the IFG via a strong ventral pathway consisting of the inferior longitudinal fasciculus (ILF) and the inferior fronto-occipital fasciculus (IFOF) in its posterior portion, and the extreme capsule (EmC) in the anterior portion (Fig. 5A), as confirmed with a standard white matter atlas
- The aSTG was also connected to the IFG via a dorsal pathway, but the aSTG–IFG connectivity displayed a higher pathway probability (PP) via the ventral compared with the dorsal pathway (t14 = 18.874, P = 2.35 × 10−11) (Fig. 3D).
- The aSTG finally showed a connection to the left frontal operculum (fOP) by dorsal pathways. Unlike the aSTG, the left polare plane (PPo) and the posterior STG (pSTG) were connected to both the IFG and the fOP only via dorsal pathways. The strongest CP originating from the STG seed regions was actually found for the pSTG and targeting all frontal regions (main effect for the factor temporal seed: F1.44,20.16 = 7.469, P = 0.007, GreenhouseGeisser (GG) corrected), especially for the comparison of the pSTG compared with the PPo (planned posthoc comparison: P = 7.74 × 10−4).
- we found that while all subregions in the STG were connected to the right fOP via dorsal pathways, only the most posterior region in the right fundus of the posterior superior temporal sulcus (fpSTS) was connected to the right IFG via equally strong dorsal and ventral pathways (i.e. indicated by a nonsignificant effect of for the comparison of the dorsal and ventral PP; t14 = 0.023, P = 0.982) as well as to the fOP via a dorsal pathway.
- The right PPo, mid STG (mSTG), and pSTG were connected only to the fOP via dorsal pathways. The least CP was found for the mSTG, especially as compared with the pSTG and the PPo
- we revealed some left-hemispheric temporofrontal connections for affective prosody processing, especially dorsal connection between the anterior STG and the inferior frontal cortex, in addition to those described recently for auditory processing of vocalizations and speech (Ethofer et al., 2012; Glasser and Rilling, 2008; Rauschecker and Scott, 2009; Saur et al., 2008)
- we now provide quantitative description as well as evidence for the specific subregions in STC and IFC, which are structurally connected by the right ventral pathway. Second, we found an overall bilateral predominance of the dorsal pathway for processing affective prosody.

Methods used by Frühholz: 
- In order to estimate the relative connectivity of the dorsal and the ventral pathways, we then conducted two additional analyses on the second stage. We included waypoint masks for the dorsal and the ventral pathway, which constrained the tracking algorithm to fibers that only passed through the respective masks (Fig. 2). These dorsal and ventral waypoint masks were generated as follows. First, we defined superior longitudinal fasciculus (SLF) masks taken from the JHU white-matter tractography atlas at a probability threshold of 100% (Hua et al., 2008). The SLF is the main dorsal longitudinal fiber bundle connecting posterior and anterior brain regions, as has been frequently reported to contain fiber connections between regions involved in auditory communication (Hua et al., 2008) (Fig. 2A). Furthermore, we defined a white-matter mask by combining the inferior longitudinal fasciculus (ILF) and the inferior fronto-occipital fasciculus (IFOF) taken from the JHU atlas, as the main ventral longitudinal fiber bundles (Friederici, 2011; Saur et al., 2008). Subsequently, we created a general white-matter pathway mask by summing up all fiber pathways from all seed and target regions across all participants. The spatial overlap between this general fiber pathway mask and the SLF mask resulting from the procedure in the first step served the definition of the dorsal pathway (Fig. 2B). The overlap between the general fiber pathway mask and the combined ILF/IFOF mask served the definition of the ventral fiber pathways.


### Friederici (2011) - Physiological Reviews
Friederici, A. D. (2011). The Brain Basis of Language Processing: From Structure to Function. _Physiological Reviews_, _91_(4), 1357–1392. [https://doi.org/10.1152/physrev.00006.2011](https://doi.org/10.1152/physrev.00006.2011)

- Networks involving the temporal cortex and the inferior frontal cortex with a clear left lateralization were shown to support syntactic processes, whereas less lateralized temporo-frontal networks subserve semantic processes.

![[Friederici 2011 Figure 3.png]]

Anatomy in the auditory cortex: 
- In an attempt to specify subregions in the auditory cortex and adjacent areas in humans, researchers have relied on neuroanatomical data from non-human primates for which a core region in HG, a surrounding belt and parabelt region has been identified (213, 230). In humans, the PAC is located on the superior surface of the temporal lobe bilaterally in HG. Three regions can be identified adjacent to HG. A region located posterior, the planum temporale (PT), a region anterolateral to HG called planum polare (PP), and a region at the lateral convexity of the cortex in the STG extending to the superior temporal sulcus (STS). All these regions are involved in the acoustic analysis of speech. Cytoarchitectonic studies have indicated that the PAC usually covers the medial two-thirds of the anterior HG (176), and the identification of a subregion in the lateral convexity of the STG has been confirmed by a receptorarchitectonic analysis (175).

![[Friederici 2011 Table 1 MNI coordinates.png]]

frequencies: 
- Hickok and Poeppel (118) proposed that the left and right hemisphere generally work at different frequencies, leading to a relative lateralization of functions.

results: 
- PAC in the left and the right hemispheres are responding to speech and tonal pitch, but they appear to have different computational preferences, with the left PAC reacting specifically to speech sounds characteristics and the right PAC to characteristics of tonal pitch (265). The relative specialization of the two auditory cortices for these stimulus types, which differ in their temporal and spectral characteristics, is described as a specialization for rapidly changing information with a limited frequency resolution in the left hemisphere and a system with reverse characteristics in the right hemisphere.

### Andere Aussagen aus paper
[[Was bedeuten die Vergleiche aus Glasser SUPPL]]


Alpha-frequency tagging

>However, remarkably, both visual and auditory frequency tagged responses amplified in anticipation of auditory targets, correlating with alpha activity amplitude. Our findings suggest that when attention shifts to auditory processing, the visual stream remains responsive and is not hindered by occipital alpha activity. This implies that alpha modulation does not solely regulate ‘gain control’ in early visual areas but rather orchestrates signal transmission to later stages of the processing stream.

aus:
Brickwedde Marion, Limachya Rupali, Markiewicz Roksana, Sutton Emma, Postzich Christopher, Shapiro Kimron, Jensen Ole, Mazaheri Ali (2025) Cross-modal interaction of Alpha Activity does not reflect inhibition of early sensory processing: A frequency tagging study using EEG and MEG eLife 14:RP106050

https://doi.org/10.7554/eLife.106050.2

![[Glasser HCP-MMP1 human brain lateral view.png]]


So soll meine Tabelle auch aussehen: 

![[Soyuhos Baldauf 2022 Tabelle Ventral, dorsal stream.png]]


### Ventral Regions 
LBelt
PBelt
STGa
STSva/STSvp
TGv
BA45
IFJa

![[ventral auditory pathway regions.png]]

### Dorsal Regions
![[dorsal auditory stream reagions.png]]
PBelt*
[[MBelt]]/LBelt*
[[A4]]
A5
MT
MST
BA44
FEF
TPOJ1
STV
PSL
TGv
TGd
PGi
7AL
7PC
PFcm


### Glasser vs andere Atlanten und Regionen 

A1 -> BA41 (Neuroscience, Paradiso, 2016), located im STG 
#### DORSAL
pST
A4/5 -> pST? 
PGi, PSL, STV -> IPL (BA40)
TPOJ1, TPOJ2 -> IPL (BA39)

### VENTRAL

## see also
Tags: #cognitivescience/neuroscience #science 
*Superlink:* [[050 🧠Neuroscience]] 

Eventuelles Side-Project: 
[[Projekt, Virtuelle Implantate im Resting-State fMRI]]
[[Wie werden auditive Reize im Gehirn verarbeitet?]]

Wenn ich meine mündliche anmelden will: 
https://www.uni-osnabrueck.de/fileadmin/fb8/ikw/Studieren/documents/Anmeldung_studienbegleitende_Pruefung_Bachelor_Jan2023_alle.pdf

https://www.uni-osnabrueck.de/fb8/ikw/institut/personal

### Fragen an meinen Prof 

- [x] schauen wir uns Working Memory and oder rein resting-state? 
- [x] unterschied zwischen functional connectivity und effective connectivity und diffusion tractography --> ist das relevant? 
- [x] ![[BA All Sources#^579d43]]
- [ ] 
## Source
Rolls, E. T., Rauschecker, J. P., Deco, G., Huang, C.-C., & Feng, J. (2023). Auditory cortical connectivity in humans. _Cerebral Cortex_, _33_(10), 6207–6227. [https://doi.org/10.1093/cercor/bhac496](https://doi.org/10.1093/cercor/bhac496)



Meeting 24.10. 

pöppel 2004 what and where 
PNAS 2006 

Liste liefern, welche Areale zu What and Where gehören 
die spezifisch auf auditory stimuli reagieren 


Werden nicht Glasser nutzen - schauen, wo es ist im gehirn

6 Paper wären schon gut 

high PFC mehr untereinander und weniger zu gabelung von what and where 

hauptsächlich functional connectivity

preferential connectivity 



Created: 2025-08-19 12:50

